#!/usr/bin/env -S uv --quiet run --script
# /// script
# requires-python = ">=3.10"
# dependencies = [
# ]
# ///

# mdb-anno-schema

#!/usr/bin/env python3
"""
annotate_schema.py

Dump the schema of an Access .mdb, annotate inline FK relationships,
add inline rowCount comments, omit empty tables, sort tables by descending rowCount,
align fieldName, fieldType, and comments into vertical columns,
and optionally print up to N sample rows per table with simple column alignment.
Sample rows: only non-numeric values are quoted or escaped based on presence of quotes.
Supports composite-FK position, nondefault grbit flags, deduplicates FKs, annotates reverse-FK references.
"""
import sys
import subprocess
import csv
import re
import io
import argparse
from collections import defaultdict

def decode_grbit(grbit):
    flags = []
    if grbit & 1:
        flags.append("RI")
    if grbit & 256:
        flags.append("CascadeUpdate")
    if grbit & 512:
        flags.append("CascadeDelete")
    return flags


def fetch_sample_rows(mdb_file, table, n):
    proc = subprocess.Popen(["mdb-export", mdb_file, table], stdout=subprocess.PIPE, text=True)
    reader = csv.reader(proc.stdout)
    samples = []
    header = next(reader, None)
    for i, row in enumerate(reader):
        if i >= n:
            break
        samples.append(row)
    proc.stdout.close()
    proc.wait()
    return [header] + samples if header else samples


def format_rows(rows, indent='    '):
    if not rows:
        return []
    quoted = []
    num_re = re.compile(r'^-?\d+(?:\.\d+)?$')
    for row in rows:
        new = []
        for cell in row:
            s = str(cell)
            # replace control chars with escape sequences
            s = s.replace('\n', '\\n').replace('\r', '\\r').replace('\t', '\\t')
            # numeric test
            if num_re.match(s):
                new.append(s)
            else:
                # quote or escape
                if '"' in s and "'" in s:
                    dbl = s.count('"'); sng = s.count("'")
                    if dbl <= sng:
                        s = '"' + s.replace('"', '\\"') + '"'
                    else:
                        s = "'" + s.replace("'", "\\'") + "'"
                else:
                    if '"' not in s:
                        s = '"' + s + '"'
                    else:
                        s = "'" + s + "'"
                new.append(s)
        quoted.append(new)
    cols = list(zip(*quoted))
    widths = [max(len(str(c)) for c in col) for col in cols]
    lines = []
    for row in quoted:
        parts = [str(cell).ljust(widths[i]) for i, cell in enumerate(row)]
        line = indent + ' '.join(parts)
        lines.append(line.rstrip() + '\n')
    return lines


def main():
    parser = argparse.ArgumentParser(description="Annotate MDB schema with FKs and sample rows.")
    parser.add_argument('mdb_file', help='Path to .mdb file')
    parser.add_argument('-n', '--rows', type=int, default=0,
                        help='Print up to N sample rows per table')
    args = parser.parse_args()
    mdb_file = args.mdb_file
    sample_n = args.rows

    # 1) List tables and compute row counts via csv
    tables = subprocess.check_output(["mdb-tables", "-1", mdb_file], text=True).splitlines()
    row_counts = {}
    for tbl in tables:
        tbl = tbl.strip()
        if not tbl:
            continue
        proc = subprocess.Popen(["mdb-export", mdb_file, tbl], stdout=subprocess.PIPE, text=True)
        reader = csv.reader(proc.stdout)
        header = next(reader, None)
        count = sum(1 for _ in reader)
        proc.stdout.close()
        proc.wait()
        row_counts[tbl] = count
    include_tables = {tbl for tbl, cnt in row_counts.items() if cnt > 0}

    # 2) Load FKs
    rels = defaultdict(list)
    reverse_rels = defaultdict(list)
    seen = set()
    rel_csv = subprocess.check_output(["mdb-export", mdb_file, "MSysRelationships"], text=True)
    reader = csv.DictReader(io.StringIO(rel_csv))
    for r in reader:
        ct, cc = r['szObject'], r['szColumn']
        pt, pc = r['szReferencedObject'], r['szReferencedColumn']
        key = (ct, cc, pt, pc)
        if key in seen: continue
        seen.add(key)
        seq = int(r.get('icolumn','0') or 0)
        ccol = int(r.get('ccolumn','0') or 0)
        gr = int(r.get('grbit','0') or 0)
        rels[ct].append({'seq': seq, 'child': cc, 'parent_tbl': pt, 'parent_col': pc, 'ccolumn': ccol, 'grbit': gr})
        if ct in include_tables:
            reverse_rels[(pt, pc)].append((ct, cc, ccol, seq, gr))

    # 3) Split DDL
    ddl = subprocess.check_output(["mdb-schema", mdb_file], text=True)
    blocks, cur = [], None
    tn = None
    for line in ddl.splitlines(keepends=True):
        el = line.expandtabs(4)
        if re.match(r'^\s*\(\s*$', el): el = '(\n'
        m = re.match(r'^CREATE TABLE \[(.+?)\]', el)
        if m:
            tn = m.group(1); cur = [el]
        elif cur is not None:
            cur.append(el)
        if cur and el.strip().endswith(');'):
            blocks.append((tn, cur)); cur = None

    # 4) Annotate blocks
    annotated = []
    for tbl, lines in blocks:
        if tbl not in include_tables: continue
        cnt = row_counts[tbl]
        fk_map = defaultdict(list)
        for fk in sorted(rels.get(tbl, []), key=lambda x: x['seq']):
            note = f"{fk['parent_tbl']}.{fk['parent_col']}"
            if fk['ccolumn']>1: note += f"({fk['seq']}/{fk['ccolumn']})"
            flags = decode_grbit(fk['grbit'])
            if flags: note += ' [' + ','.join(flags) + ']'
            fk_map[fk['child']].append(note)
        ann, first = [], True
        for ln in lines:
            if first:
                ann.append(ln.rstrip('\r\n')+f" -- rowCount = {cnt}\n"); first=False; continue
            el = ln.expandtabs(4)
            mcol = re.match(r'^(?P<p>\s*\[[^]]+\]\s*[^,]*,)(?:\s*)(?P<c>--.*)?$', el)
            if mcol:
                p = mcol.group('p'); cn = re.match(r'^\s*\[([^]]+)\]',p).group(1)
                cmt = mcol.group('c') or ''
                if cn in fk_map:
                    cmt = '-- FK -> ' + '; '.join(fk_map[cn]); fk_map.pop(cn)
                rev = reverse_rels.get((tbl,cn), [])
                if rev:
                    notes = []
                    for ct, cc, ccol, seq, gr in rev:
                        txt = f"{ct}.{cc}" + (f"({seq}/{ccol})" if ccol>1 else '')
                        fl = decode_grbit(gr)
                        if fl: txt += ' [' + ','.join(fl) + ']'
                        notes.append(txt)
                    cmt = (cmt + ' ' if cmt else '-- ') + 'FK <- ' + ' '.join(notes)
                ann.append(p + (' ' + cmt if cmt else '') + '\n')
            else:
                ann.append(ln)
        annotated.append((tbl, ann))

    # 5) Align schema
    aligned = []
    for tbl, lines in annotated:
        ents, mn, mt = [], 0, 0
        for i, l in enumerate(lines):
            el=l.expandtabs(4)
            m=re.match(r'^(?P<i>\s*)(?P<n>\[[^]]+\])\s+(?P<t>[^,]+,?)(?:\s*)(?P<c>--.*)?$', el)
            if not m: continue
            ind, nm, ty, cm = m.group('i'), m.group('n'), m.group('t'), m.group('c') or ''
            ents.append((i, ind, nm, ty, cm))
            mn=max(mn,len(ind+nm)); mt=max(mt,len(ty))
        nl=list(lines)
        for i, ind, nm, ty, cm in ents:
            nf=ind+nm.ljust(mn-len(ind)); tf=ty.ljust(mt)
            nl[i] = (f"{nf} {tf} {cm}" if cm else f"{nf} {tf}").rstrip() + '\n'
        aligned.append((tbl, nl))

    # 6) Output + samples
    aligned.sort(key=lambda x: row_counts[x[0]], reverse=True)
    out = mdb_file + '_annotated_schema.sql'
    with open(out,'w') as f:
        for tbl, lines in aligned:
            for ln in lines: f.write(ln)
            if sample_n>0:
                rows=fetch_sample_rows(mdb_file,tbl,sample_n)
                if rows:
                    f.write('\n    -- Sample rows:\n')
                    for r in format_rows(rows): f.write(r)
                    f.write('\n')
    print(f"Annotated schema with samples written to: {out}")

if __name__=='__main__': main()
