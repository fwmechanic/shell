#!/usr/bin/env -S uv --quiet run --script
# /// script
# requires-python = ">=3.10"
# dependencies = [
# ]
# ///

# mdb-anno-schema

#!/usr/bin/env python3
"""
annotate_schema.py

Dump the schema of an Access .mdb, annotate inline FK relationships,
add inline rowCount comments, omit empty tables, sort tables by descending rowCount,
and align fieldName, fieldType, and comments into vertical columns.
Supports composite-FK position, nondefault grbit flags, deduplicates FKs.
"""
import sys
import subprocess
import csv
import re
import io
from collections import defaultdict

def decode_grbit(grbit):
    flags = []
    if grbit & 1:
        flags.append("RI")
    if grbit & 256:
        flags.append("CascadeUpdate")
    if grbit & 512:
        flags.append("CascadeDelete")
    return flags

def main():
    if len(sys.argv) != 2:
        print(f"Usage: {sys.argv[0]} path/to/file.mdb", file=sys.stderr)
        sys.exit(1)
    mdb_file = sys.argv[1]

    # 1) List tables and compute row counts
    tables = subprocess.check_output(["mdb-tables", "-1", mdb_file], text=True).splitlines()
    row_counts = {}
    for tbl in tables:
        tbl = tbl.strip()
        if not tbl:
            continue
        lines = subprocess.check_output(["mdb-export", mdb_file, tbl], text=True).splitlines()
        row_counts[tbl] = max(len(lines) - 1, 0)
    include_tables = {tbl for tbl, cnt in row_counts.items() if cnt > 0}

    # 2) Load and dedupe MSysRelationships
    rels = defaultdict(list)
    seen = set()
    rel_csv = subprocess.check_output(["mdb-export", mdb_file, "MSysRelationships"], text=True)
    reader = csv.DictReader(io.StringIO(rel_csv))
    for r in reader:
        key = (r['szObject'], r['szColumn'], r['szReferencedObject'], r['szReferencedColumn'])
        if key in seen:
            continue
        seen.add(key)
        rels[r['szObject']].append({
            'seq': int(r.get('icolumn','0') or 0),
            'child': r['szColumn'],
            'parent_tbl': r['szReferencedObject'],
            'parent_col': r['szReferencedColumn'],
            'ccolumn': int(r.get('ccolumn','0') or 0),
            'grbit': int(r.get('grbit','0') or 0)
        })

    # 3) Dump raw DDL and split into table blocks
    schema = subprocess.check_output(["mdb-schema", mdb_file], text=True)
    blocks = []
    cur = None
    tbl_name = None
    for line in schema.splitlines(keepends=True):
        el = line.expandtabs(4)
        # normalize lone '(' lines (remove leading spaces)
        if re.match(r'^\s*\(\s*$', el):
            el = '(\n'
        m = re.match(r'^CREATE TABLE \[(.+?)\]', el)
        if m:
            tbl_name = m.group(1)
            cur = [el]
        elif cur is not None:
            cur.append(el)
        if cur and el.strip().endswith(');'):
            blocks.append((tbl_name, cur))
            cur = None

    # 4) Annotate each block with rowCount and FK comments
    annotated_blocks = []
    for tbl, lines in blocks:
        if tbl not in include_tables:
            continue
        cnt = row_counts[tbl]
        fk_map = defaultdict(list)
        for fk in sorted(rels.get(tbl, []), key=lambda x: x['seq']):
            note = f"{fk['parent_tbl']}.{fk['parent_col']}"
            if fk['ccolumn'] > 1:
                note += f"({fk['seq']}/{fk['ccolumn']})"
            flags = decode_grbit(fk['grbit'])
            if flags:
                note += ' [' + ','.join(flags) + ']'
            fk_map[fk['child']].append(note)

        ann = []
        first = True
        for line in lines:
            if first:
                line = line.rstrip('\r\n') + f" -- rowCount = {cnt}\n"
                first = False
                ann.append(line)
                continue
            mcol = re.match(r'^(?P<prefix>\s*\[[^]]+\]\s*[^,]*,)(?:\s*)(?P<comment>--.*)?$', line.expandtabs(4))
            if mcol:
                prefix = mcol.group('prefix')
                col = re.match(r'^\s*\[([^]]+)\]', prefix).group(1)
                comment = mcol.group('comment') or ''
                if col in fk_map:
                    comment = '-- FK -> ' + '; '.join(fk_map[col])
                    fk_map.pop(col)
                line = prefix + (' ' + comment if comment else '') + '\n'
            ann.append(line)
        annotated_blocks.append((tbl, ann))

    # 5) Align columns within blocks to three vertical columns
    aligned_blocks = []
    for tbl, lines in annotated_blocks:
        entries = []  # (idx, indent, name, typec, comment)
        max_name = 0
        max_type = 0
        for idx, line in enumerate(lines):
            el = line.expandtabs(4)
            m = re.match(r'^(?P<indent>\s*)(?P<name>\[[^]]+\])\s*(?P<type>[^,]+,?)\s*(?P<comment>--.*)?$', el)
            if not m:
                continue
            indent = m.group('indent')
            name = m.group('name')
            typec = m.group('type')
            comment = m.group('comment') or ''
            entries.append((idx, indent, name, typec, comment))
            max_name = max(max_name, len(indent + name))
            max_type = max(max_type, len(typec))
        new_lines = list(lines)
        for idx, indent, name, typec, comment in entries:
            name_field = indent + name.ljust(max_name - len(indent))
            type_field = typec.ljust(max_type)
            if comment:
                new_line = f"{name_field} {type_field} {comment}\n"
            else:
                # no trailing spaces after type
                new_line = (name_field + ' ' + type_field).rstrip() + '\n'
            new_lines[idx] = new_line
        aligned_blocks.append((tbl, new_lines))

    # 6) Sort by rowCount and write output
    aligned_blocks.sort(key=lambda x: row_counts[x[0]], reverse=True)
    out_path = mdb_file + '_annotated_schema.sql'
    with open(out_path, 'w') as f:
        for _, lines in aligned_blocks:
            for ln in lines:
                f.write(ln)
    print(f"Annotated schema written to: {out_path}")

if __name__ == '__main__':
    main()
